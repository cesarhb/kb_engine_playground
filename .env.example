# Postgres + pgvector (default for Docker Compose)
DATABASE_URL=postgresql://kb_engine:kb_engine_secret@postgres:5432/kb_engine

# Embeddings: "ollama" (local) or "openai" (set OPENAI_API_KEY)
# Ollama: use mxbai-embed-large (keep_alive 5m to avoid hogging VRAM)
EMBEDDING_PROVIDER=ollama
EMBEDDING_MODEL=mxbai-embed-large

# Optional: for EMBEDDING_PROVIDER=openai
# OPENAI_API_KEY=sk-...

# LLM for the RAG agent: "ollama" (local) or "openai"
LLM_PROVIDER=ollama
LLM_MODEL=llama3.2

# Optional: for LLM_PROVIDER=openai
# OPENAI_API_KEY=sk-...

# Ollama: when using the included docker-compose or dev container, Ollama runs in a
# dedicated container and OLLAMA_BASE_URL is set for you (http://ollama:11434).
# Only set this if you run Ollama on the host (e.g. http://host.docker.internal:11434).
# OLLAMA_BASE_URL=http://localhost:11434

# Optional: for github_repo doc sources (higher API rate limits)
# GITHUB_PERSONAL_ACCESS_TOKEN=ghp_...
