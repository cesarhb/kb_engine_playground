services:
  postgres:
    image: pgvector/pgvector:pg16
    environment:
      POSTGRES_USER: kb_engine
      POSTGRES_PASSWORD: kb_engine_secret
      POSTGRES_DB: kb_engine
    ports:
      - "5432:5432"
    volumes:
      - pgdata:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U kb_engine -d kb_engine"]
      interval: 5s
      timeout: 5s
      retries: 5

  ollama:
    image: ollama/ollama
    volumes:
      - ollama:/root/.ollama
    ports:
      - "11435:11434"  # 11435 on host to avoid conflict with host Ollama

  ingestion:
    build: .
    command: ["python", "-m", "src.ingestion.pipeline"]
    env_file: .env
    environment:
      PYTHONUNBUFFERED: "1"
      DATABASE_URL: postgresql://kb_engine:kb_engine_secret@postgres:5432/kb_engine
      OLLAMA_BASE_URL: http://ollama:11434
      EMBEDDING_MODEL: mxbai-embed-large
    depends_on:
      postgres:
        condition: service_healthy
      ollama:
        condition: service_started

  agent:
    build: .
    env_file: .env
    # Run with full CLI: docker compose run --rm agent python -m src.cli search "query" -k 5
    # Or: docker compose run --rm agent python -m src.cli cli "Your question?"
    # Server: docker compose run --rm -p 8123:8123 agent python -m src.cli server
    command: ["python", "-m", "src.cli"]
    environment:
      PYTHONUNBUFFERED: "1"
      DATABASE_URL: postgresql://kb_engine:kb_engine_secret@postgres:5432/kb_engine
      OLLAMA_BASE_URL: http://ollama:11434
      EMBEDDING_MODEL: mxbai-embed-large
      PORT: "8123"
    depends_on:
      postgres:
        condition: service_healthy
      ollama:
        condition: service_started
    ports:
      - "8123:8123"

volumes:
  pgdata:
    external: true
    name: kb_engine_playground_pgdata
  ollama:
    external: true
    name: kb_engine_playground_ollama